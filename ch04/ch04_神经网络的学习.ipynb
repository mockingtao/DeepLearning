{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0781feec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-20T08:55:52.564521Z",
     "start_time": "2022-10-20T08:55:52.177746Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import pickle\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell \n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9edf56e",
   "metadata": {},
   "source": [
    "# 数据驱动的基本思路与损失函数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0b2ce8",
   "metadata": {},
   "source": [
    "## 数据驱动的基本思路\n",
    "\n",
    "我们先用一个不严谨的例子，对数据学习有一点感性上的认识\n",
    "\n",
    "假设有Y = AX + B\n",
    "\n",
    "我们已知 X, Y 的值，求A和B，思路是：\n",
    "\n",
    "### 第一步：训练\n",
    "随机给一个 $A_1$, $B_1$，计算出 $Y_{p1}$，得到与正确预测的差值 |$Y$ - $Y_{p1}$|， p在这里是predict的缩写。\n",
    "\n",
    "调整权重为 $A_2$, $B_2$，得到 $Y_{p2}$，并有 |$Y$ - $Y_{p2}$| < |$Y$ - $Y_{p1}$|\n",
    "\n",
    "重复这个过程：直到预测的 $Y_{pn}$ 与已知Y的差距越来越小，这时的$A_{n}$ ，$B_{n}$ 就是我们求得的参数\n",
    "\n",
    "### 第二步：测试 $Y=A_nX + B_n$\n",
    "\n",
    "再来一组已知数据 $X_{2}$ ，$Y_{2}$，测试|$Y_{2} - Y_{p}$| 以判断函数的准确性\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067693e1",
   "metadata": {},
   "source": [
    "### 基本概念的引入\n",
    "\n",
    "可见在这个过程中，我们只需要知道X，Y的数据，而二者之间的关系，则由机器自动推算出来。其中：\n",
    "\n",
    "$X_1$, $Y_1$ 为 **训练数据**\n",
    "\n",
    "$X_2$， $Y_2$ 为 **测试数据**\n",
    "\n",
    "|$Y_{1} - Y_{p}$| 为 **损失函数**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c1d610",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-18T08:04:00.588364Z",
     "start_time": "2022-10-18T08:04:00.567944Z"
    }
   },
   "source": [
    "### 传统思维方式，机器学习 和 神经网络（深度学习）的区别\n",
    "\n",
    "如图：\n",
    "<img src=\"img/0402.png\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    "\n",
    "神经网络或深度学习则比以往的机器学习方法更能避免人为介入。与待处理的问题无关，神经网络可以将数据直接作为原始数据，进行“端对端”的学习。\n",
    "\n",
    "#### 传统机器学习步骤：\n",
    "人为设计一些特征值，再通过机器学习SVM，KNN 来实现；\n",
    "\n",
    "#### 神经网络学习步骤：\n",
    "直接学习图像本身\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f8a872",
   "metadata": {},
   "source": [
    "## 损失函数\n",
    "\n",
    "- 神经网络的学习通过某个指标表示现在的状态。然后，以这个指标为基准，寻找最优权重参数。\n",
    "\n",
    "- 神经网络以某个指标为线索寻找最优权重参数\n",
    "\n",
    "- 神经网络的学习中所用的指标称为损失函数（loss function）。\n",
    "\n",
    "- 损失函数是表示神经网络性能的“恶劣程度”的指标，即当前的神经网络对监督数据在多大程度上不拟合，在多大程度上不一致\n",
    "\n",
    "- 这个损失函数可以使用任意函数，但一般用均方误差和交叉熵误差等。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccedb602",
   "metadata": {},
   "source": [
    "### 均方误差MSE（mean squared error）\n",
    "\n",
    "#### 公式 ：$E = \\frac{1}{2}\\sum\\limits_k(y_k - t_k)^2 $\n",
    "$y_k$是表示神经网络的输出，$t_k$表示监督数据，k表示数据的维数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87d59c17",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-20T08:28:05.879360Z",
     "start_time": "2022-10-20T08:28:05.871299Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09750000000000003\n",
      "0.9025\n"
     ]
    }
   ],
   "source": [
    "# 例1：在节手写数字识别的例子中，yk、tk是由如下10个元素构成的数据。\n",
    "import numpy as np\n",
    "\n",
    "y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0] # 0~9 数字的概率\n",
    "t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "def mean_squared_error(y, t):\n",
    "    return 0.5 * np.sum((y-t)**2)\n",
    "\n",
    "error = mean_squared_error(np.array(y), np.array(t))\n",
    "\n",
    "# 这里是error，越小说明误差越小，表示结果越准；\n",
    "print(error)\n",
    "print(1-error) # 准确率在90%，这里反了一个错误，不能单纯的直接用 1- error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1c725e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 关于y：\n",
    "# 数组元素的索引从第一个开始依次对应数字“0”“1”“2”…… \n",
    "# 这里，神经网络的输出y是softmax函数的输出。\n",
    "# 由于softmax函数的输出可以理解为概率，\n",
    "# 因此上例表示“0”的概率是0.1，“1”的概率是0.05，“2”的概率是0.6等。\n",
    "\n",
    "# 关于t：\n",
    "# t是监督数据，将正确解标签设为1，其他均设为0。\n",
    "# 这里，标签“2”为1，表示正确解是“2”。\n",
    "# 将正确解标签表示为1，其他标签表示为0的表示方法称为one-hot表示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a493c5bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-20T08:28:23.328944Z",
     "start_time": "2022-10-20T08:28:23.320527Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5975"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # 例2：t不变，修改y：“7”的概率最高的情况（0.6）,t 的正确解还是2\n",
    "y2 = [0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0]\n",
    "mean_squared_error(np.array(y2), np.array(t))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848f075a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-18T02:40:05.324535Z",
     "start_time": "2022-10-18T02:40:05.317834Z"
    }
   },
   "source": [
    "### 交叉熵误差(cross entropy error)\n",
    "\n",
    "#### 公式： $E = -\\sum\\limits_k t_k log y_k $\n",
    "\n",
    "- log表示以e为底数的自然对数（$log_e$）, $y_k$是神经网络的输出，$t_k$是正确解标签。\n",
    "\n",
    "- $t_k$中只有正确解标签的索引为1，其他均为0（one-hot表示）。\n",
    "\n",
    "- 因此，交叉熵公式实际上只计算对应正确解标签的输出的自然对数。\n",
    "\n",
    "比如，假设正确解标签的索引是“2”，与之对应的神经网络的输出是0.6，则交叉熵误差是−log 0.6 = 0.51；\n",
    "若“2”对应的输出是0.1，则交叉熵误差为−log 0.1 = 2.30。也就是说，交叉熵误差的值是由正确解标签所对应的输出结果决定的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "cc94bdb6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-18T09:14:35.204866Z",
     "start_time": "2022-10-18T09:14:35.041141Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-105-102c02e36cda>:7: RuntimeWarning: divide by zero encountered in log\n",
      "  y = -np.log(x)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 看一下-log(x) 函数\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "x = np.arange(0, 1, 0.001)\n",
    "y = -np.log(x)\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.ylim(0, 5.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e14032",
   "metadata": {},
   "source": [
    "对应到公式中：$E = -\\sum\\limits_k t_k log y_k $\n",
    "\n",
    "正确解标签对应的输出越大，公式中的值越接近0（也就是误差越小）。以至于当输出为1时，交叉熵误差E为0。\n",
    "\n",
    "如果正确解标签对应的输出较小，则公式的值较大，则误差E越大。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd27ca62",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-20T08:29:23.727540Z",
     "start_time": "2022-10-20T08:29:23.723124Z"
    }
   },
   "outputs": [],
   "source": [
    "# 代码实现交叉熵误差\n",
    "def cross_entropy_error(y, t):\n",
    "    delta = 1e-7\n",
    "    return -np.sum(t * np.log(y + delta))\n",
    "\n",
    "# 函数内部在计算np.log时，加上了一个极小值delta。\n",
    "# 这是因为，当出现np.log(0)时，np.log(0)会变为负无限大的-inf，这样一来就会导致后续计算无法进行。\n",
    "# 作为保护性对策，添加一个微小值可以防止负无限大的发生。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca3636a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-20T08:29:25.626641Z",
     "start_time": "2022-10-20T08:29:25.617968Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.510825457099338\n",
      "0.489174542900662\n"
     ]
    }
   ],
   "source": [
    "# 第一个例子，正确解标签对应的输出为0.6，此时的交叉熵误差大约为0.51\n",
    "\n",
    "t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
    "y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]\n",
    "error = cross_entropy_error(np.array(y), np.array(t))\n",
    "print(error)\n",
    "print(1-error)\n",
    "\n",
    "# 误差为0.51...\n",
    "\n",
    "# cc：感觉这个误差不太适合这个例子。\n",
    "# 该例子y值与t值比较接近的。但是error 达到了51%... -- 这里不能这么理解。这里是error值并不是error 率；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48a3440e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-20T08:30:59.989787Z",
     "start_time": "2022-10-20T08:30:59.983823Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.302584092994546\n",
      "-1.3025840929945458\n"
     ]
    }
   ],
   "source": [
    "# 第二个例子，正确解标签对应的输出为0.1的低值，此时的交叉熵误差大约为2.3\n",
    "\n",
    "y = [0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0]\n",
    "error = cross_entropy_error(np.array(y), np.array(t))\n",
    "print(error)\n",
    "print(1-error)\n",
    "# 误差为 2.3..\n",
    "\n",
    "# 这个error更加离谱；\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "c6e81728",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-18T11:04:46.844298Z",
     "start_time": "2022-10-18T11:04:46.831304Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -2.30258409  -2.99573027  -0.51082546 -16.11809565  -2.99573027\n",
      "  -2.30258409 -16.11809565  -2.30258409 -16.11809565 -16.11809565]\n",
      "[-0.         -0.         -0.51082546 -0.         -0.         -0.\n",
      " -0.         -0.         -0.         -0.        ]\n",
      "0.510825457099338\n"
     ]
    }
   ],
   "source": [
    "# 详细解读：-np.sum(t * np.log(y + delta))\n",
    "\n",
    "delta = 1e-7\n",
    "print(np.log(np.array(y) + delta))\n",
    "\n",
    "print(np.array(t)*np.log(np.array(y) + delta))\n",
    "\n",
    "print(-np.sum(np.array(t)*np.log(np.array(y) + delta)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9ae10a",
   "metadata": {},
   "source": [
    "### mini-batch学习\n",
    "\n",
    "神经网络的学习也是从训练数据中选出一批数据（称为mini-batch,小批量），然后对每个mini-batch进行学习。\n",
    "\n",
    "比如，从60000个训练数据中随机\n",
    "选择100笔，再用这100笔数据进行学习。这种学习方式称为mini-batch学习。\n",
    "\n",
    "#### 公式：$E = \\frac{1}{N}\\sum\\limits_{n} \\sum\\limits_{k} t_{nk} log y_{nk} $\n",
    "\n",
    "这里,假设数据有N个，$t_{nk}$表示第n个数据的第k个元素的值（$y_{nk}$是神经网络的输出，$t_{nk}$是监督数据）。\n",
    "\n",
    "其实只是把求单个数据的损失函数扩大到了N份数据，最后除以N进行正规化。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8971d7d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-20T08:52:30.176893Z",
     "start_time": "2022-10-20T08:52:30.171858Z"
    }
   },
   "outputs": [],
   "source": [
    "# mini-batch版交叉熵误差的实现\n",
    "def cross_entropy_error(y, t):\n",
    "    if y.ndim == 1: # 如果是一维数组，变成二维数据；\n",
    "        t = t.reshape(1, t.size)\n",
    "        y = y.reshape(1, y.size)\n",
    "        \n",
    "    print(y.shape[0])    \n",
    "    batch_size = y.shape[0]\n",
    "    return -np.sum(t * np.log(y + 1e-7)) / batch_size\n",
    "\n",
    "# 非batch：-np.sum(t * np.log(y + 1e-7))\n",
    "\n",
    "# 其中，1e-7 为极小值，如果不加这个值，当y=0的时候，log返回的结果是无穷大。会报错！"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f637d8d",
   "metadata": {},
   "source": [
    "这里，y是神经网络的输出，t是监督数据。\n",
    "\n",
    "y的维度为1时，即求单个数据的交叉熵误差时，需要改变数据的形状。\n",
    "\n",
    "并且，当输入为mini-batch时，要用batch的个数进行正规化，计算单个数据的平均交叉熵误差。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4574a4b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-20T08:52:31.907249Z",
     "start_time": "2022-10-20T08:52:31.896658Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10,)\n",
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.510825457099338"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 如果y为1维：\n",
    "y1 = np.array([0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0])\n",
    "\n",
    "print(y1.shape)# 这还是一维数组；\n",
    "t1 = np.array([0, 0, 1, 0, 0, 0, 0, 0, 0, 0])\n",
    "\n",
    "cross_entropy_error(y1, t1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c4e46ba7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-20T08:50:42.394284Z",
     "start_time": "2022-10-20T08:50:42.387308Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 10)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2 = y1.reshape(1, y1.size)\n",
    "y2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "024f84ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-20T08:53:39.999468Z",
     "start_time": "2022-10-20T08:53:39.985069Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.406704775046942"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 如果y为多维\n",
    "y2 = np.array([[0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0],\n",
    "               [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0],\n",
    "               [0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0],\n",
    "               [0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0]])\n",
    "# 这里把y2中的值稍加改动；\n",
    "\n",
    "t2 = np.array([[0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
    "               [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
    "               [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
    "               [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]])\n",
    "\n",
    "cross_entropy_error(y2, t2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "335b1fa9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-18T10:56:43.494401Z",
     "start_time": "2022-10-18T10:56:43.483484Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -2.30258409  -2.99573027  -0.51082546 -16.11809565  -2.99573027\n",
      "   -2.30258409 -16.11809565  -2.30258409 -16.11809565 -16.11809565]\n",
      " [ -2.30258409  -2.99573027  -0.51082546 -16.11809565  -2.99573027\n",
      "   -2.30258409 -16.11809565  -2.30258409 -16.11809565 -16.11809565]\n",
      " [ -2.30258409  -2.99573027  -2.30258409 -16.11809565  -2.99573027\n",
      "   -2.30258409 -16.11809565  -0.51082546 -16.11809565 -16.11809565]\n",
      " [ -2.30258409  -2.99573027  -2.30258409 -16.11809565  -2.99573027\n",
      "   -2.30258409 -16.11809565  -0.51082546 -16.11809565 -16.11809565]]\n",
      "[[-0.         -0.         -0.51082546 -0.         -0.         -0.\n",
      "  -0.         -0.         -0.         -0.        ]\n",
      " [-0.         -0.         -0.51082546 -0.         -0.         -0.\n",
      "  -0.         -0.         -0.         -0.        ]\n",
      " [-0.         -0.         -2.30258409 -0.         -0.         -0.\n",
      "  -0.         -0.         -0.         -0.        ]\n",
      " [-0.         -0.         -2.30258409 -0.         -0.         -0.\n",
      "  -0.         -0.         -0.         -0.        ]]\n",
      "1.406704775046942\n"
     ]
    }
   ],
   "source": [
    "# 详细解读： -np.sum(t * np.log(y + 1e-7)) / batch_size\n",
    "batch_size = 4\n",
    "print(np.log(y2 + 1e-7))\n",
    "\n",
    "print(t2 * np.log(y2 + 1e-7))\n",
    "\n",
    "print(-np.sum(t2 * np.log(y2 + 1e-7))/ batch_size)\n",
    "# -(-0.51082546-0.51082546-2.30258409-2.30258409)/4 = 5.6268191/4 = 1.406704775046942"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "c994a80f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-18T10:49:10.153350Z",
     "start_time": "2022-10-18T10:49:10.141180Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.406704775046942"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 另，当监督数据是标签形式（非one-hot表示，而是像“2”“7”这样的标签）时，优化实现：\n",
    "\n",
    "def cross_entropy_error2(y, t):\n",
    "    if y.ndim == 1:\n",
    "        t = t.reshape(1, t.size)\n",
    "        y = y.reshape(1, y.size)\n",
    "        \n",
    "    batch_size = y.shape[0]\n",
    "    return -np.sum(np.log(y[np.arange(batch_size), t] + 1e-7)) / batch_size\n",
    "\n",
    "# 结果\n",
    "y3 = np.array([[0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0],\n",
    "               [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0],\n",
    "               [0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0],\n",
    "               [0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0]])\n",
    "# 这里把y2中的值稍加改动；\n",
    "t3 = np.array([2,2,2,2])\n",
    "\n",
    "# 最终输出：\n",
    "cross_entropy_error2(y3,t3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "870c1224",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-20T08:57:03.936111Z",
     "start_time": "2022-10-20T08:57:03.925958Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 步骤详解：\n",
    "batch_size = y3.shape[0]\n",
    "np.arange(batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "189d12af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-20T09:00:30.611277Z",
     "start_time": "2022-10-20T09:00:30.603834Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.05, 0.6 , 0.1 , 0.1 ])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t3 = np.array([4,2,2,2])\n",
    "\n",
    "y3[np.arange(batch_size), t3] # 6666：数组的切片，第一个（逗号前）为取行，第二个为取列。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2c5ac8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8223f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f1e768",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab03f1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "da734fd2",
   "metadata": {},
   "source": [
    "### 回到MNIST数据集 的例子，我们取数来看下\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62d4b1a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-20T08:39:40.398219Z",
     "start_time": "2022-10-20T08:39:40.085552Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(60000, 10)\n"
     ]
    }
   ],
   "source": [
    "# 回到MNIST数据集 的例子，我们取数来看下，\n",
    "\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "import numpy as np\n",
    "from dataset.mnist import load_mnist\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
    "print(x_train.shape) # (60000, 784)\n",
    "print(t_train.shape) # (60000, 10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03c3ec0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-18T11:14:59.362374Z",
     "start_time": "2022-10-18T11:14:59.351301Z"
    }
   },
   "source": [
    "读入MNIST数据后，训练数据有60000个，输入数据是784维 （28 × 28）的图像数据，监督数据是10维的数据。因此，上面的x_train、t_\n",
    "train的形状分别是(60000, 784)和(60000, 10)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47fc0485",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-20T08:40:26.764606Z",
     "start_time": "2022-10-20T08:40:26.754279Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "[ 5615 54776  1594  1767 56660 24890 49607  1081 29085 37547]\n"
     ]
    }
   ],
   "source": [
    "# 从这个训练数据中随机抽取10笔数据\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 10\n",
    "batch_mask = np.random.choice(train_size, batch_size) # 从0到59999之间随机选择10个数字\n",
    "print(train_size)\n",
    "print(batch_mask)\n",
    "\n",
    "x_batch = x_train[batch_mask]\n",
    "t_batch = t_train[batch_mask]\n",
    "# print(x_batch)\n",
    "# print(t_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd0b228e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-20T08:40:57.326336Z",
     "start_time": "2022-10-20T08:40:57.319946Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_batch.shape\n",
    "\n",
    "x_batch[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d851d80",
   "metadata": {},
   "source": [
    "之后，我们只需指定这些随机选出的索引，取出mini-batch，然后使用这个mini-batch计算损失函数即可。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24492aaa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-18T11:18:24.646746Z",
     "start_time": "2022-10-18T11:18:24.630650Z"
    }
   },
   "source": [
    "### 为何要设定损失函数\n",
    "\n",
    "在进行神经网络的学习时，不能将识别精度作为指标。因为**如果以识别精度为指标，则参数的导数在绝大多数地方都会变为0。**\n",
    "\n",
    "#### 为什么用识别精度作为指标时，参数的导数在绝大多数地方都会变成0？\n",
    "答案：假设某个神经网络正确识别出了100笔训练数据中的32笔，此时识别精度为32 %。如果以识别精度为指标，即使稍微改变权重参数的值，识别精度也仍将保持在32 %，不会出现变化。也就是说，仅仅微调参数，是无法改善识别精度的。即便识别精度有所改善，它的值也不会像32.0123 ... %这样连续变化，而是变为33 %、34 %这样的不连续的、离散的值。而如果把损失函数作为指标，则当前损失函数的值可以表示为0.92543 ... 这样的值。并且，如果稍微改变一下参数的值，对应的损失函数也会像0.93432 ... 这样发生连续性的变化。\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"img/0404.png\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    "\n",
    "识别精度对微小的参数变化基本上没有什么反应，即便有反应，它的值也是不连续地、突然地变化。\n",
    "作为激活函数的阶跃函数也有同样的情况。出于相同的原因，如果使用阶跃函数作为激活函数，神经网络的学习将无法进行。\n",
    "\n",
    "如上图所示，阶跃函数的导数在绝大多数地方（除了0以外的地方）均为0。\n",
    "也就是说，如果使用了阶跃函数，那么即便将损失函数作为指标，参数的微小变化也会被阶跃函数抹杀，导致损失函数的值不会产生任何变化。\n",
    "\n",
    "而sigmoid函数，不仅函数的输出（竖轴的值）是连续变化的，曲线的斜率（导数）也是连续变化的。也就是说，sigmoid函数的导数在任何地方都不为0。这对神经网络的学习非常重要。得益于这个斜率不会为0的性质，神经网络的学习得以正确进行。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4acbee6f",
   "metadata": {},
   "source": [
    "# 数值微分\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0398e885",
   "metadata": {},
   "source": [
    "## 导数\n",
    "导数就是表示某个瞬间的变化量。它可以定义成下面的式子。\n",
    "\n",
    "$$\\frac{df(x)}{dx}= \\lim\\limits_{h\\rightarrow0}\\frac{f(x+h)-f(x)}{h} $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "0b33afa0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-18T12:27:21.799003Z",
     "start_time": "2022-10-18T12:27:21.789058Z"
    }
   },
   "outputs": [],
   "source": [
    "# 中心差分实现数值微分\n",
    "\n",
    "def numerical_diff(f, x):\n",
    "    h = 1e-4 # 0.0001,使用过小的值会造成计算机出现计算上的问题，发生“舍入误差”，反而舍入为0.0\n",
    "    return (f(x+h) - f(x-h)) / (2*h)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f6acc9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-18T12:25:12.309252Z",
     "start_time": "2022-10-18T12:25:12.280585Z"
    }
   },
   "source": [
    "利用微小的差分求导数的过程称为数值微分，如以上的 numerical_diff 计算结果；--- 近似导数\n",
    "\n",
    "而基于数学式的推导求导数的过程，则用“解析性”（analytic）一词，称为“解析性求解”或者“解析性求导”。--- “真的导数”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "e5eabda3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-18T12:26:16.024862Z",
     "start_time": "2022-10-18T12:26:15.794386Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 例子\n",
    "\n",
    "def function_1(x):\n",
    "    return 0.01*x**2 + 0.1*x\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "x = np.arange(0.0, 20.0, 0.1) # 以0.1为单位，从0到20的数组x\n",
    "y = function_1(x)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"f(x)\")\n",
    "plt.plot(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "beedde99",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-18T12:27:24.590988Z",
     "start_time": "2022-10-18T12:27:24.580900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1999999999990898\n",
      "0.2999999999986347\n"
     ]
    }
   ],
   "source": [
    "# 计算导数\n",
    "print(numerical_diff(function_1, 5))\n",
    "print(numerical_diff(function_1, 10))\n",
    "\n",
    "#  在x = 5 和 x = 10处，通过解析解得到的“真的导数”分别为0.2和0.3。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b09fde",
   "metadata": {},
   "source": [
    "## 偏导数\n",
    "\n",
    "我们把多个变量的函数的导数称为偏导数。\n",
    "\n",
    "不过，偏导数需要将多个变量中的某一个变量定为目标变量，并将其他变量固定为某个值。\n",
    "\n",
    "在下例的代码中，为了将目标变量以外的变量固定到某些特定的值上，我们定义了新函数。\n",
    "\n",
    "然后，对新定义的函数应用了之前的求数值微分的函数，得到偏导数。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5413a96a",
   "metadata": {},
   "source": [
    "求某个变量x0偏导的时候，实际上和x1没有任何关系。偏导只是代表函数在某个变量上的变化情况（切线斜率）；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "d620f825",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-18T13:05:42.534971Z",
     "start_time": "2022-10-18T13:05:42.529985Z"
    }
   },
   "outputs": [],
   "source": [
    "# 多元方程式\n",
    "\n",
    "# 有两个变量x\n",
    "def function_2(x):\n",
    "    return x[0]**2 + x[1]**2 # 或者可以写成：return np.sum(x**2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d850533a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-18T12:45:12.780549Z",
     "start_time": "2022-10-18T12:45:12.769720Z"
    }
   },
   "source": [
    "问题1：求x0 = 3, x1 = 4时，关于x0的偏导数 ${{\\partial}f}\\over{{\\partial}{x_0}}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "70c1cfcc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-18T12:42:17.499464Z",
     "start_time": "2022-10-18T12:42:17.486219Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.00000000000378"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def function_tmp1(x0):\n",
    "    return x0*x0 + 4.0**2.0\n",
    "\n",
    "numerical_diff(function_tmp1, 3.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fa3dfb",
   "metadata": {},
   "source": [
    "问题2：求x0 = 3, x1 = 4时，关于x1的偏导数 ${{\\partial}f}\\over{{\\partial}{x_1}}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "1df591ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-18T12:49:35.020231Z",
     "start_time": "2022-10-18T12:49:35.000858Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.999999999999119"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def function_tmp2(x1):\n",
    "    return 3.0**2.0 + x1*x1\n",
    "\n",
    "numerical_diff(function_tmp2, 4.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc77c10b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-18T12:51:06.450058Z",
     "start_time": "2022-10-18T12:51:06.444702Z"
    }
   },
   "source": [
    "# 梯度\n",
    "\n",
    "在刚才的例子中，我们按变量分别计算了x0和x1的偏导数。\n",
    "\n",
    "如果将两个偏导汇总形成一个值，称为梯度。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "be1a1bfd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-18T13:05:35.642639Z",
     "start_time": "2022-10-18T13:05:35.622830Z"
    }
   },
   "outputs": [],
   "source": [
    "# 梯度实现的代码\n",
    "\n",
    "def numerical_gradient(f, x):\n",
    "    h = 1e-4 # 0.0001\n",
    "    grad = np.zeros_like(x) # 生成和x形状相同的数组[0,0]，比如这里X[3,4]，说明有两个变量，则由两个方向；\n",
    "    \n",
    "    for idx in range(x.size): # 如X[3, 4], idx = 0, 1，迭代两次，分别计算两个方向的梯度值；\n",
    "        tmp_val = x[idx] # tmp_val = X[0] = 3\n",
    "        \n",
    "        # f(x+h)的计算\n",
    "        x[idx] = tmp_val + h # X[0]=3+h, X变为[3+h, 4]\n",
    "        fxh1 = f(x) # 算 [3+h, 4]对应的f\n",
    "        \n",
    "        # f(x-h)的计算\n",
    "        x[idx] = tmp_val - h # X为[3-h, 4]\n",
    "        fxh2 = f(x) # 算 [3-h, 4] 对应的f\n",
    "        grad[idx] = (fxh1 - fxh2) / (2*h) # 得到梯度\n",
    "        x[idx] = tmp_val # 还原X为[3, 4]\n",
    "    \n",
    "    return grad\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "b6bfdea5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-18T13:09:26.452071Z",
     "start_time": "2022-10-18T13:09:26.441354Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6. 8.]\n",
      "[0. 4.]\n",
      "[6. 0.]\n"
     ]
    }
   ],
   "source": [
    "# 调用\n",
    "print(numerical_gradient(function_2, np.array([3.0, 4.0])))\n",
    "print(numerical_gradient(function_2, np.array([0.0, 2.0])))\n",
    "print(numerical_gradient(function_2, np.array([3.0, 0.0])))\n",
    "\n",
    "# 梯度指示的方向是各点处的函数值减小最多的方向 A。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d3f846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 直接整理成笔记的效率有点慢，还是先以书本和代码理解为主。\n",
    "# 后续复习的时候再整理笔记。\n",
    "# 先在书中把关键信息标记下来。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "10f68679",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-19T02:53:30.619594Z",
     "start_time": "2022-10-19T02:53:30.546209Z"
    }
   },
   "outputs": [],
   "source": [
    "# 梯度下降法实现\n",
    "\n",
    "def gradient_descent(f, init_x, lr=0.01, step_num=100):\n",
    "    x = init_x\n",
    "    for i in range(step_num):\n",
    "        grad = numerical_gradient(f, x) # 这里f为损失函数，损失函数是表示error与w的关系表达式，所以这里x实际是w\n",
    "        x -= lr * grad\n",
    "    return x\n",
    "\n",
    "# 参数f是要进行最优化的函数\n",
    "# init_x是初始值，\n",
    "# lr是学习率learning rate，\n",
    "# step_num是梯度法的重复次数\n",
    "\n",
    "# numerical_gradient(f,x)会求函数的梯度，用该梯度乘以学习率得到的值进行更新操作，\n",
    "#由step_num指定重复的次数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "de947562",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-19T02:53:36.655421Z",
     "start_time": "2022-10-19T02:53:36.623749Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-6.11110793e-10,  8.14814391e-10])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 问题：请用梯度法求 以下的最小值。\n",
    "\n",
    "def function_2(x):\n",
    "    return x[0]**2 + x[1]**2\n",
    "\n",
    "init_x = np.array([-3.0, 4.0])\n",
    "\n",
    "gradient_descent(function_2, init_x=init_x, lr=0.1, step_num=100)\n",
    "\n",
    "# 可见最终输出是两个极小值，趋近于(0, 0)，实际最终的结果就是(0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "d1c7a6b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-19T02:57:48.525624Z",
     "start_time": "2022-10-19T02:57:48.297614Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 所有代码 + 绘图\n",
    "\n",
    "def numerical_gradient(f, x):\n",
    "    h = 1e-4 # 0.0001\n",
    "    grad = np.zeros_like(x) # 生成和x形状相同的数组[0,0]\n",
    "    \n",
    "    for idx in range(x.size): # 如X[3, 4], idx = 0, 1\n",
    "        tmp_val = x[idx] # tmp_val = X[0] = 3\n",
    "        \n",
    "        # f(x+h)的计算\n",
    "        x[idx] = tmp_val + h # X[0]=3+h, X变为[3+h, 4]\n",
    "        fxh1 = f(x) # 算 [3+h, 4]对应的f\n",
    "        \n",
    "        # f(x-h)的计算\n",
    "        x[idx] = tmp_val - h # X为[3-h, 4]\n",
    "        fxh2 = f(x) # 算 [3-h, 4] 对应的f\n",
    "        grad[idx] = (fxh1 - fxh2) / (2*h) # 得到梯度\n",
    "        x[idx] = tmp_val # 还原X为[3, 4]\n",
    "    \n",
    "    return grad\n",
    "    \n",
    "\n",
    "def gradient_descent(f, init_x, lr=0.01, step_num=100):\n",
    "    x = init_x\n",
    "    x_history = []\n",
    "\n",
    "    for i in range(step_num):\n",
    "        x_history.append( x.copy() )\n",
    "\n",
    "        grad = numerical_gradient(f, x)\n",
    "        x -= lr * grad\n",
    "\n",
    "    return x, np.array(x_history)\n",
    "\n",
    "\n",
    "def function_2(x):\n",
    "    return x[0]**2 + x[1]**2\n",
    "\n",
    "init_x = np.array([-3.0, 4.0])    \n",
    "\n",
    "lr = 0.1\n",
    "step_num = 20\n",
    "x, x_history = gradient_descent(function_2, init_x, lr=lr, step_num=step_num)\n",
    "\n",
    "plt.plot( [-5, 5], [0,0], '--b')\n",
    "plt.plot( [0,0], [-5, 5], '--b')\n",
    "plt.plot(x_history[:,0], x_history[:,1], 'o')\n",
    "\n",
    "plt.xlim(-3.5, 3.5)\n",
    "plt.ylim(-4.5, 4.5)\n",
    "plt.xlabel(\"X0\")\n",
    "plt.ylabel(\"X1\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e663018b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-20T09:24:28.028678Z",
     "start_time": "2022-10-20T09:24:28.021739Z"
    }
   },
   "outputs": [],
   "source": [
    "# 简单的神经网络为例，来实现求梯度的代码\n",
    "\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "import numpy as np\n",
    "from common.functions import softmax, cross_entropy_error\n",
    "from common.gradient import numerical_gradient\n",
    "\n",
    "\n",
    "class simpleNet:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.W = np.random.randn(2,3) # 用高斯分布进行初始化\n",
    "        \n",
    "    def predict(self, x):\n",
    "        return np.dot(x, self.W)\n",
    "    \n",
    "    def loss(self, x, t):\n",
    "        z = self.predict(x)\n",
    "        y = softmax(z)\n",
    "        print(y)\n",
    "        print(t)\n",
    "        loss = cross_entropy_error(y, t)\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f425d960",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-20T09:24:30.192277Z",
     "start_time": "2022-10-20T09:24:30.175806Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.78240672 -0.72482534  0.41793289]\n",
      " [-0.63161628 -3.13229807  0.09347381]]\n",
      "[-1.03789868 -3.25396346  0.33488616]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.19780974 0.02156865 0.7806216 ]\n",
      "[0 0 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.24766461951233104"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# simpleNet 简单试用\n",
    "net = simpleNet()\n",
    "print(net.W) # 权重参数\n",
    "\n",
    "x = np.array([0.6, 0.9])\n",
    "p = net.predict(x)\n",
    "print(p)\n",
    "\n",
    "np.argmax(p) # 最大值的索引\n",
    "t = np.array([0, 0, 1]) # 正确解标签\n",
    "net.loss(x, t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "caa80cb4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-20T09:28:39.324265Z",
     "start_time": "2022-10-20T09:28:39.318164Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "5b580852",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-19T05:00:41.447467Z",
     "start_time": "2022-10-19T05:00:41.436947Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.0148434   0.52709932 -0.54194272]\n",
      " [ 0.0222651   0.79064898 -0.81291408]]\n"
     ]
    }
   ],
   "source": [
    "# 求一次梯度；\n",
    "def f(W):\n",
    "    return net.loss(x, t)\n",
    "\n",
    "dW = numerical_gradient(f, net.W)\n",
    "print(dW)\n",
    "\n",
    "# 拿过来放在一起看；\n",
    "def numerical_gradient(f, x):\n",
    "    h = 1e-4 # 0.0001\n",
    "    grad = np.zeros_like(x) # 生成和x形状相同的数组[0,0]\n",
    "    \n",
    "    for idx in range(x.size): # 如X[3, 4], idx = 0, 1\n",
    "        tmp_val = x[idx] # tmp_val = X[0] = 3\n",
    "        \n",
    "        # f(x+h)的计算\n",
    "        x[idx] = tmp_val + h # X[0]=3+h, X变为[3+h, 4]\n",
    "        fxh1 = f(x) # 算 [3+h, 4]对应的f\n",
    "        \n",
    "        # f(x-h)的计算\n",
    "        x[idx] = tmp_val - h # X为[3-h, 4]\n",
    "        fxh2 = f(x) # 算 [3-h, 4] 对应的f\n",
    "        grad[idx] = (fxh1 - fxh2) / (2*h) # 得到梯度\n",
    "        x[idx] = tmp_val # 还原X为[3, 4]\n",
    "    \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ad3ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如果将w11增加h，那么损失函数的值会增加0.0148434h\n",
    "# 如果将w23增加h，损失函数的值将减小0.81291408h\n",
    "\n",
    "# 因此，w23应向正方向更新，w11应向负方向更新。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "2e870bf1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-19T05:10:29.968000Z",
     "start_time": "2022-10-19T05:10:29.959401Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.0148434   0.52709932 -0.54194272]\n",
      " [ 0.0222651   0.79064898 -0.81291408]]\n"
     ]
    }
   ],
   "source": [
    "# 使用匿名函数\n",
    "f = lambda w: net.loss(x, t)\n",
    "dW = numerical_gradient(f, net.W)\n",
    "print(dW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "18d1c825",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-20T09:53:39.817612Z",
     "start_time": "2022-10-20T09:53:39.791604Z"
    }
   },
   "outputs": [],
   "source": [
    "# 　2层神经网络的类\n",
    "\n",
    "# coding: utf-8\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 为了导入父目录的文件而进行的设定\n",
    "from common.functions import *\n",
    "from common.gradient import numerical_gradient\n",
    "\n",
    "\n",
    "class TwoLayerNet:\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, output_size, weight_init_std=0.01):\n",
    "        # 初始化权重\n",
    "        self.params = {}\n",
    "        self.params['W1'] = weight_init_std * np.random.randn(input_size, hidden_size)\n",
    "        self.params['b1'] = np.zeros(hidden_size)\n",
    "        self.params['W2'] = weight_init_std * np.random.randn(hidden_size, output_size)\n",
    "        self.params['b2'] = np.zeros(output_size)\n",
    "\n",
    "    def predict(self, x):\n",
    "        W1, W2 = self.params['W1'], self.params['W2']\n",
    "        b1, b2 = self.params['b1'], self.params['b2']\n",
    "    \n",
    "        a1 = np.dot(x, W1) + b1\n",
    "        z1 = sigmoid(a1)\n",
    "        a2 = np.dot(z1, W2) + b2\n",
    "        y = softmax(a2)\n",
    "        \n",
    "        return y\n",
    "        \n",
    "    # x:输入数据, t:监督数据\n",
    "    def loss(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        \n",
    "        return cross_entropy_error(y, t)\n",
    "    \n",
    "    def accuracy(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        y = np.argmax(y, axis=1)\n",
    "        t = np.argmax(t, axis=1)\n",
    "        \n",
    "        accuracy = np.sum(y == t) / float(x.shape[0])\n",
    "        return accuracy\n",
    "        \n",
    "    # x:输入数据, t:监督数据\n",
    "    def numerical_gradient(self, x, t):\n",
    "        loss_W = lambda W: self.loss(x, t)\n",
    "        \n",
    "        grads = {}\n",
    "        grads['W1'] = numerical_gradient(loss_W, self.params['W1'])\n",
    "        grads['b1'] = numerical_gradient(loss_W, self.params['b1'])\n",
    "        grads['W2'] = numerical_gradient(loss_W, self.params['W2'])\n",
    "        grads['b2'] = numerical_gradient(loss_W, self.params['b2'])\n",
    "        \n",
    "        return grads\n",
    "        \n",
    "    def gradient(self, x, t):\n",
    "        W1, W2 = self.params['W1'], self.params['W2']\n",
    "        b1, b2 = self.params['b1'], self.params['b2']\n",
    "        grads = {}\n",
    "        \n",
    "        batch_num = x.shape[0]\n",
    "        \n",
    "        # forward\n",
    "        a1 = np.dot(x, W1) + b1\n",
    "        z1 = sigmoid(a1)\n",
    "        a2 = np.dot(z1, W2) + b2\n",
    "        y = softmax(a2)\n",
    "        \n",
    "        # backward\n",
    "        dy = (y - t) / batch_num\n",
    "        grads['W2'] = np.dot(z1.T, dy)\n",
    "        grads['b2'] = np.sum(dy, axis=0)\n",
    "        \n",
    "        da1 = np.dot(dy, W2.T)\n",
    "        dz1 = sigmoid_grad(a1) * da1\n",
    "        grads['W1'] = np.dot(x.T, dz1)\n",
    "        grads['b1'] = np.sum(dz1, axis=0)\n",
    "\n",
    "        return grads\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "16f35f76",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-20T09:53:41.592983Z",
     "start_time": "2022-10-20T09:53:41.578848Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 100)\n",
      "(100,)\n",
      "(100, 10)\n",
      "(10,)\n"
     ]
    }
   ],
   "source": [
    "# 调用例子\n",
    "net = TwoLayerNet(input_size=784, hidden_size=100, output_size=10)\n",
    "print(net.params['W1'].shape) # (784, 100)\n",
    "print(net.params['b1'].shape) # (100,)\n",
    "print(net.params['W2'].shape) # (100, 10)\n",
    "print(net.params['b2'].shape) # (10,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8defc6fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-20T09:54:34.208850Z",
     "start_time": "2022-10-20T09:54:34.198701Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.10689113, 0.09360812, 0.09900285, 0.09998252, 0.09274198,\n",
       "       0.09969959, 0.09994772, 0.10001975, 0.11210157, 0.09600477])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.random.rand(100, 784)\n",
    "y = net.predict(x)\n",
    "y[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "11596a67",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-20T09:54:50.625081Z",
     "start_time": "2022-10-20T09:54:50.616909Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9402597 , 0.77989162, 0.14493632, 0.35425338, 0.7849047 ,\n",
       "       0.84045893, 0.28298879, 0.32401365, 0.77052823, 0.94910892])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.random.rand(100, 784) # 伪输入数据（100笔）\n",
    "t = np.random.rand(100, 10) # 伪正确解标签（100笔）\n",
    "t[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7ae716df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-20T10:01:07.628463Z",
     "start_time": "2022-10-20T10:01:07.613630Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([ 2.35080420e-04, -7.86968268e-07,  1.42966239e-04, -3.87139454e-05,\n",
       "       -2.50371621e-04, -6.06256534e-05,  2.14879778e-04, -1.46152299e-04,\n",
       "       -1.16898837e-04,  1.03067932e-05,  2.31952473e-04, -3.17198554e-04,\n",
       "       -1.00226631e-04,  1.13721881e-04,  2.61797879e-04,  2.85568733e-04,\n",
       "       -1.19585657e-04,  1.59234883e-04, -7.88432741e-05, -1.82541138e-05,\n",
       "        2.31669319e-04,  9.12904796e-05,  1.18289103e-04, -1.25979642e-04,\n",
       "        3.51191920e-05,  2.47360672e-04, -1.96860737e-04,  3.70688915e-04,\n",
       "        6.40643938e-05,  7.93253019e-05, -4.11845957e-05,  1.65310610e-04,\n",
       "       -1.10451357e-04,  7.16503590e-05,  1.85701707e-04, -3.17720381e-04,\n",
       "        7.78715115e-05,  6.76504941e-05,  8.91042817e-05,  3.85254784e-05,\n",
       "        3.49359253e-05,  2.52500727e-04,  3.24401357e-04, -1.67646885e-04,\n",
       "       -1.79980506e-04,  2.00272665e-05, -1.37948790e-04, -6.85874180e-05,\n",
       "       -1.08104390e-04, -2.57485027e-04, -1.05442073e-04, -3.08348713e-04,\n",
       "       -1.98236294e-05,  2.29498491e-04, -2.66419642e-05,  8.95413921e-05,\n",
       "       -1.82153186e-04,  4.30738145e-04, -1.58326818e-05, -1.13428542e-04,\n",
       "       -3.82081966e-05, -7.96659916e-05,  7.15585347e-05, -1.34914131e-04,\n",
       "        5.12663045e-05,  1.88022264e-06, -1.67475300e-04,  1.21848418e-04,\n",
       "       -2.21992713e-04,  4.83679630e-05,  2.75295073e-04, -1.59870233e-04,\n",
       "       -3.30675582e-04, -1.06509110e-04,  2.86094060e-05,  1.72635861e-05,\n",
       "        2.92164106e-04,  3.13384456e-04,  3.94021948e-05,  3.01166374e-04,\n",
       "        8.27704882e-05,  2.07439799e-05,  1.00048387e-04, -5.20393062e-05,\n",
       "        9.54904444e-05, -1.30065603e-05,  4.55363236e-05, -1.70626273e-04,\n",
       "       -3.22657951e-04,  8.25695379e-05,  1.93729903e-04,  1.35625611e-04,\n",
       "        1.29547657e-04, -1.82081610e-04,  2.94117659e-04,  2.05139232e-04,\n",
       "        1.46747059e-07,  9.91657423e-05,  1.37642358e-04,  3.36986239e-04])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# grads = net.numerical_gradient(x, t)\n",
    "grads['W1'][0].shape\n",
    "\n",
    "grads['W1'][0]\n",
    "\n",
    "# 这里只是计算了各个参数W，b 的梯度，还没有更新W 和 b值；\n",
    "\n",
    "# 拿过来再看一下。\n",
    "# def numerical_gradient(self, x, t):\n",
    "#     loss_W = lambda W: self.loss(x, t)\n",
    "\n",
    "#     grads = {}\n",
    "#     grads['W1'] = numerical_gradient(loss_W, self.params['W1'])\n",
    "#     grads['b1'] = numerical_gradient(loss_W, self.params['b1'])\n",
    "#     grads['W2'] = numerical_gradient(loss_W, self.params['W2'])\n",
    "#     grads['b2'] = numerical_gradient(loss_W, self.params['b2'])\n",
    "\n",
    "#     return grads\n",
    "\n",
    "\n",
    "# def loss(self, x, t):\n",
    "#     y = self.predict(x)\n",
    "#     return cross_entropy_error(y, t)\n",
    "\n",
    "\n",
    "# def predict(self, x):\n",
    "#     W1, W2 = self.params['W1'], self.params['W2']\n",
    "#     b1, b2 = self.params['b1'], self.params['b2']\n",
    "\n",
    "#     a1 = np.dot(x, W1) + b1\n",
    "#     z1 = sigmoid(a1)\n",
    "#     a2 = np.dot(z1, W2) + b2\n",
    "#     y = softmax(a2)\n",
    "\n",
    "#     return y\n",
    "\n",
    "\n",
    "# def numerical_gradient(f, x):\n",
    "#     h = 1e-4 # 0.0001\n",
    "#     grad = np.zeros_like(x)\n",
    "    \n",
    "#     it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
    "#     while not it.finished:\n",
    "#         idx = it.multi_index\n",
    "#         tmp_val = x[idx]\n",
    "#         x[idx] = float(tmp_val) + h\n",
    "#         fxh1 = f(x) # f(x+h)\n",
    "        \n",
    "#         x[idx] = tmp_val - h \n",
    "#         fxh2 = f(x) # f(x-h)\n",
    "#         grad[idx] = (fxh1 - fxh2) / (2*h)\n",
    "        \n",
    "#         x[idx] = tmp_val # 还原值\n",
    "#         it.iternext()   \n",
    "        \n",
    "#     return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b6547f42",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-20T10:15:34.900260Z",
     "start_time": "2022-10-20T10:15:34.552410Z"
    }
   },
   "outputs": [],
   "source": [
    "# 　mini-batch的实现\n",
    "import numpy as np\n",
    "from dataset.mnist import load_mnist\n",
    "from two_layer_net import TwoLayerNet\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label = True)\n",
    "train_loss_list = []\n",
    "\n",
    "# 超参数\n",
    "iters_num = 10000 # 迭代次数\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 100\n",
    "learning_rate = 0.1\n",
    "\n",
    "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3c6f9c5f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-20T10:19:44.567814Z",
     "start_time": "2022-10-20T10:19:22.384167Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(iters_num):\n",
    "    # 获取mini-batch\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = x_train[batch_mask]\n",
    "    t_batch = t_train[batch_mask]\n",
    "    \n",
    "    # 计算梯度\n",
    "#     grad = network.numerical_gradient(x_batch, t_batch)\n",
    "    grad = network.gradient(x_batch, t_batch) # 高速版!\n",
    "    \n",
    "    # 更新参数\n",
    "    for key in ('W1', 'b1', 'W2', 'b2'):\n",
    "        network.params[key] -= learning_rate * grad[key]\n",
    "    \n",
    "    # 记录学习过程\n",
    "    loss = network.loss(x_batch, t_batch)\n",
    "    train_loss_list.append(loss)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b9c9ec2f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-20T10:20:44.220756Z",
     "start_time": "2022-10-20T10:20:43.995049Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7faaabfa24f0>]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e72383b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-20T11:36:29.494338Z",
     "start_time": "2022-10-20T11:36:29.258668Z"
    }
   },
   "outputs": [],
   "source": [
    "# 基于测试数据的评价\n",
    "\n",
    "import numpy as np\n",
    "from dataset.mnist import load_mnist\n",
    "from two_layer_net import TwoLayerNet\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label = True)\n",
    "\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "\n",
    "# 平均每个epoch的重复次数\n",
    "iter_per_epoch = max(train_size / batch_size, 1)\n",
    "\n",
    "# 超参数\n",
    "iters_num = 10000\n",
    "batch_size = 100\n",
    "learning_rate = 0.1\n",
    "\n",
    "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2d91b0b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-20T11:40:47.086513Z",
     "start_time": "2022-10-20T11:40:18.056832Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc, test acc | 0.10441666666666667, 0.1028\n",
      "train acc, test acc | 0.7796166666666666, 0.7881\n",
      "train acc, test acc | 0.87785, 0.8824\n",
      "train acc, test acc | 0.8988, 0.902\n",
      "train acc, test acc | 0.9082833333333333, 0.9111\n",
      "train acc, test acc | 0.9156333333333333, 0.9172\n",
      "train acc, test acc | 0.91995, 0.9203\n",
      "train acc, test acc | 0.9246166666666666, 0.9246\n",
      "train acc, test acc | 0.9278833333333333, 0.9297\n",
      "train acc, test acc | 0.93275, 0.9329\n",
      "train acc, test acc | 0.9343666666666667, 0.9347\n",
      "train acc, test acc | 0.9378, 0.9368\n",
      "train acc, test acc | 0.9395666666666667, 0.9398\n",
      "train acc, test acc | 0.9418166666666666, 0.9393\n",
      "train acc, test acc | 0.9431833333333334, 0.9421\n",
      "train acc, test acc | 0.9446833333333333, 0.9439\n",
      "train acc, test acc | 0.9470333333333333, 0.9448\n"
     ]
    }
   ],
   "source": [
    "for i in range(iters_num):\n",
    "    # 获取mini-batch\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = x_train[batch_mask]\n",
    "    t_batch = t_train[batch_mask]\n",
    "    \n",
    "    # 计算梯度\n",
    "#     grad = network.numerical_gradient(x_batch, t_batch)\n",
    "    grad = network.gradient(x_batch, t_batch) # 高速版!\n",
    "    \n",
    "    # 更新参数\n",
    "    for key in ('W1', 'b1', 'W2', 'b2'):\n",
    "        network.params[key] -= learning_rate * grad[key]\n",
    "    \n",
    "    loss = network.loss(x_batch, t_batch)\n",
    "    train_loss_list.append(loss)\n",
    "    \n",
    "    # 计算每个epoch的识别精度\n",
    "    if i % iter_per_epoch == 0:\n",
    "        train_acc = network.accuracy(x_train, t_train)\n",
    "        test_acc = network.accuracy(x_test, t_test)\n",
    "        train_acc_list.append(train_acc)\n",
    "        test_acc_list.append(test_acc)\n",
    "        print(\"train acc, test acc | \" + str(train_acc) + \", \" + str(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0e96a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed714da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd72015",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26125d9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89483962",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66179457",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
