{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08374636",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-24T00:33:36.773855Z",
     "start_time": "2022-11-24T00:33:34.413444Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import pickle\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell \n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72fd223",
   "metadata": {},
   "source": [
    "# 从感知机到神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b81eaa1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-24T00:08:57.927158Z",
     "start_time": "2022-11-24T00:08:57.917726Z"
    }
   },
   "source": [
    "感知机缺点：设定权重的工作，即确定合适的、能符合预期的输入与输出的权重，现在还是由人工进行的。\n",
    "\n",
    "神经网络的一个重要性质是它可以自动地从数据中学习到合适的权重参数。\n",
    "\n",
    "本章中，我们先介绍神经网络的概要，然后重点关注神经网络进行识别时的处理。在下一章中，将了解如何从数据中学习权重参数。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b57a60",
   "metadata": {},
   "source": [
    "<img src=\"img/3_1.png\" alt=\"Drawing\" style=\"width: 300px;\"/>\n",
    "\n",
    "- 我们把最左边的一列称为\n",
    "输入层，最右边的一列称为输出层，中间的一列称为中间层。\n",
    "- 中间层有时也称为隐藏层。“隐藏”一词的意思是，隐藏层的神经元（和输入层、输出\n",
    "层不同）肉眼看不见。\n",
    "- 本书中把输入层到输出层依次称为第0层、第\n",
    "1层、第2层（层号之所以从0开始，是为了方便后面基于Python进行实现）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50fca17",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-24T00:19:38.719205Z",
     "start_time": "2022-11-24T00:19:38.683603Z"
    }
   },
   "source": [
    "神经网络的形状类似上一章的感知机。实际上，就神经元的连接方式而言，与上一章的感知机并没有任何差异。\n",
    "<img src=\"img/3_2.png\" alt=\"Drawing\" style=\"width: 300px;\"/>\n",
    "\n",
    "\n",
    "那么，神经网络与感知机差异和关系式什么？神经网络中信号是如何传递的呢？\n",
    "\n",
    "简单理解:\n",
    "- 神经网络是由感知机组成，激活函数是连接感知机和神经网络的桥梁。\n",
    "- 一般而言，“朴素感知机”是指单层网络，指的是激活函数使用了阶跃函数的模型。(阶跃函数后面讲到)\n",
    "- “多层感知机”是指神经网络，即使用 sigmoid函数（后述）等平滑的激活函数的多层网络。\n",
    "\n",
    "<img src=\"img/3_4.png\" alt=\"Drawing\" style=\"width: 300px;\"/>\n",
    "\n",
    "神经元的○中明确显示了激活函数的计算过程，即信号的加权总和为节点a，然后节点a被激活函数h()转换成节点y。\n",
    "\n",
    "<img src=\"img/3_5.png\" alt=\"Drawing\" style=\"width: 300px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8206a26d",
   "metadata": {},
   "source": [
    "# 激活函数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab98dbd5",
   "metadata": {},
   "source": [
    "会将输入信号的总和转换为输出信号，这种函数一般称为激活函数（activation function）。\n",
    "\n",
    "如“激活”一词所示，激活函数的作用在于决定如何来激活输入信号的总和。\n",
    "\n",
    "感知机中使用了阶跃函数作为激活函数;\n",
    "\n",
    "<img src=\"img/formula_3_3.png\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    "\n",
    "- 式（3.3）表示的激活函数以阈值为界，一旦输入超过阈值，就切换输出。\n",
    "\n",
    "\n",
    "如果将激活函数从阶跃函数换成其他函数，就可以进入神经网络的世界了。\n",
    "\n",
    "其他常见的激活函数：\n",
    "- sigmoid函数\n",
    "- ReLU函数\n",
    "\n",
    "接下来我们拉看具体的实现："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ca9f78",
   "metadata": {},
   "source": [
    "## 阶跃函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d6ff65a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-24T00:35:48.009320Z",
     "start_time": "2022-11-24T00:35:48.002421Z"
    }
   },
   "outputs": [],
   "source": [
    "# 阶跃函数\n",
    "def step_function(x):\n",
    "    return np.array(x>0, dtype='int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3b263ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-24T00:35:50.427147Z",
     "start_time": "2022-11-24T00:35:50.201365Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fe6709ba6d0>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(-0.1, 1.1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.arange(-5.0, 5.0, 0.1)\n",
    "y = step_function(x)\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.ylim(-0.1, 1.1) # 指定y轴的范围\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a4dab0",
   "metadata": {},
   "source": [
    "阶跃函数以0为界，输出从0切换为1（或者从1切换为0）。\n",
    "它的值呈阶梯式变化，所以称为阶跃函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5dd481a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-24T00:36:00.282295Z",
     "start_time": "2022-11-24T00:36:00.254066Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.,  1.,  2.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([False,  True,  True])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([-1.0, 1.0, 2.0])\n",
    "x\n",
    "y = x > 0\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d61d20d",
   "metadata": {},
   "source": [
    "## sigmoid函数\n",
    "\n",
    "神经网络中经常使用的一个激活函数就是sigmoid函数（sigmoid function）。\n",
    "\n",
    "公式如下：\n",
    "\n",
    "$$sigmoid =  \\frac{1}{1-e^x}$$\n",
    "\n",
    "图形如下：\n",
    "\n",
    "<img src=\"img/3_7.png\" alt=\"Drawing\" style=\"width: 300px;\"/>\n",
    "\n",
    "\n",
    "sigmoid函数的平滑性对神经网络的学习具有重要意义。\n",
    "\n",
    "向sigmoid函数输入1.0或2.0后，就会有某个值被输出，类似h(1.0) = 0.731 ...、h(2.0) = 0.880 ...这样。\n",
    "\n",
    "如下代码：np.exp()函数是求 $e^x$ 的值的函数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa384d2c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-24T00:43:29.667973Z",
     "start_time": "2022-11-24T00:43:29.420956Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fe670a85c40>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(-0.1, 1.1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def sigmoid(x):\n",
    "    return  1 / (1 + np.exp(-x)) \n",
    "\n",
    "x = np.arange(-5.0, 5.0, 0.1)\n",
    "y = sigmoid(x)\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.ylim(-0.1, 1.1) # 指定y轴的范围\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e30ab29",
   "metadata": {},
   "source": [
    "### sigmoid函数和阶跃函数的比较\n",
    "\n",
    "#### 区别\n",
    "1. 首先注意到的是“平滑性”的不同。sigmoid函数是一条平滑的曲线，输出随着输入发生连续性的变化。而阶跃函数以0为界，输出发生急剧性的变化;\n",
    "2. 相对于阶跃函数只能返回0或1，sigmoid函数可以返回0.731 ...、0.880 ...等实数（这一点和刚才的平滑性有关）。也就是说，感知机中神经元之间流动的是0或1的二元信号，而神经网络中流动的是连续的实数值信号;\n",
    "\n",
    "#### 共性\n",
    "1. 两者的结构均是“输入较小时，输出接近0（为0）；随着输入增大，输出向1靠近（变成1）”。也就是说，当输入信号为重要信息时，阶跃函数和sigmoid函数都会输出较大的值；当输入信号为不重要的信息时，两者都输出较小的值；\n",
    "2. 不管输入信号有多小，或者有多大，输出信号的值都在0到1之间；\n",
    "3. 两者均为非线性函数；（线性函数是一条笔直的直线。而非线性函数，顾名思义，指的是不像线性函数那样呈现出一条直线的函数。）\n",
    "\n",
    "    知识点补充：神经网络的激活函数必须使用非线性函数。换句话说，激活函数不能使\n",
    "用线性函数。为什么不能使用线性函数呢？因为使用线性函数的话，加深神\n",
    "经网络的层数就没有意义了。\n",
    "线性函数的问题在于，不管如何加深层数，总是存在与之等效的“无\n",
    "隐藏层的神经网络”。为了具体地（稍微直观地）理解这一点，我们来思\n",
    "考下面这个简单的例子。这里我们考虑把线性函数 h(x) = cx 作为激活\n",
    "函数，把y(x) = h(h(h(x)))的运算对应3层神经网络A。这个运算会进行\n",
    "y(x) = c × c × c × x的乘法运算，但是同样的处理可以由y(x) = ax（注意，\n",
    "a = c 3\n",
    "）这一次乘法运算（即没有隐藏层的神经网络）来表示。如本例所示，\n",
    "使用线性函数时，无法发挥多层网络带来的优势。因此，为了发挥叠加层所\n",
    "带来的优势，激活函数必须使用非线性函数。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3692aaaa",
   "metadata": {},
   "source": [
    "## ReLU函数\n",
    "\n",
    "在神经网络发展的历史上，sigmoid函数很早就开始被使用了，而最近则主要使用ReLU（Rectified Linear Unit）函数。\n",
    "\n",
    "ReLU函数在输入大于0时，直接输出该值；在输入小于等于0时，输出0，如下公式：\n",
    "\n",
    "<img src=\"img/formula_3_7.png\" alt=\"Drawing\" style=\"width: 500px;\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f6b96189",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-24T13:41:47.896347Z",
     "start_time": "2022-11-24T13:41:47.498335Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fe670b60eb0>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(-1.0, 5.5)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def relu(x):\n",
    "    return np.maximum(0,x)\n",
    "\n",
    "# maximum函数会从输入的数值中选择较大的那个值进行输出。\n",
    "\n",
    "x = np.arange(-5.0, 5.0, 0.1)\n",
    "y = relu(x)\n",
    "plt.plot(x, y)\n",
    "plt.ylim(-1.0, 5.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34d70c0",
   "metadata": {},
   "source": [
    "## 插播知识点：多维数组的运算"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3feaf9ed",
   "metadata": {},
   "source": [
    "如果掌握了NumPy多维数组的运算，就可以高效地实现神经网络。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "23cf85ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-17T08:49:00.803808Z",
     "start_time": "2022-10-17T08:49:00.794681Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "(4,)\n"
     ]
    }
   ],
   "source": [
    "A = np.array([1, 2, 3, 4])\n",
    "print(np.ndim(A))\n",
    "print(A.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f0f2139e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-16T09:10:16.310184Z",
     "start_time": "2022-10-16T09:10:16.302174Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "(3, 2)\n"
     ]
    }
   ],
   "source": [
    "B = np.array([[1,2], [3,4], [5,6]])\n",
    "print(np.ndim(B))\n",
    "print(B.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "79a3298c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-16T09:13:10.650643Z",
     "start_time": "2022-10-16T09:13:10.641342Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[19, 22],\n",
       "       [43, 50]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.array([[1,2], [3,4]])\n",
    "B = np.array([[5,6], [7,8]])\n",
    "np.dot(A, B)\n",
    "\n",
    "# cc：np.dot()接收两个NumPy数组作为参数，并返回数组的乘积。\n",
    "# 这里要注意的是，np.dot(A, B)和np.dot(B, A)的值可能不一样。\n",
    "# 和一般的运算（+或*等）不同，矩阵的乘积运算中，操作数（A、 B）的顺序不同，结果也会不同。\n",
    "# 在多维数组的乘积运算中，必须使两个矩阵中的对应维度的元素个数一致，这一点很重要！"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3379181",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-24T14:02:52.525805Z",
     "start_time": "2022-11-24T14:02:52.512831Z"
    }
   },
   "source": [
    "案例：使用NumPy矩阵来实现神经网络\n",
    "\n",
    "<img src=\"img/3_14.png\" alt=\"Drawing\" style=\"width: 500px;\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6882f335",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-24T14:01:32.660299Z",
     "start_time": "2022-11-24T14:01:32.621394Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(2,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 3, 5],\n",
       "       [2, 4, 6]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(2, 3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([ 5, 11, 17])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(3,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 神经网络的内积\n",
    "X = np.array([1, 2])\n",
    "X\n",
    "X.shape\n",
    "\n",
    "W = np.array([[1, 3, 5], [2, 4, 6]])\n",
    "W\n",
    "W.shape\n",
    "\n",
    "Y = np.dot(X, W)\n",
    "Y\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b76fb14",
   "metadata": {},
   "source": [
    "# 3层神经网络的实现\n",
    "\n",
    "先快速了解以下符号表示：\n",
    "\n",
    "<img src=\"img/3_16.png\" alt=\"Drawing\" style=\"width: 300px;\"/>\n",
    "\n",
    "- 权重和隐藏层的神经元的右上角有一个“(1)”，它表示权重和神经元的层号（即第1层的权重、第1层的神经元）。\n",
    "- 权重的右下角有两个数字，\n",
    "    - 第一个数字：后一层的神经元的索引号\n",
    "    - 第二个数据：前一层的神经元的索引号\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a6a97a",
   "metadata": {},
   "source": [
    "这里我们以图3-15的3层神经网络为对象，实现从输入到输出的（前向）处理。如图：\n",
    "\n",
    "<img src=\"img/3_15.png\" alt=\"Drawing\" style=\"width: 300px;\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53698308",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-24T14:11:50.757033Z",
     "start_time": "2022-11-24T14:11:50.730860Z"
    }
   },
   "source": [
    "## 从输入层到第1层的信号传递\n",
    "\n",
    "<img src=\"img/3_17.png\" alt=\"Drawing\" style=\"width: 300px;\"/> \n",
    "\n",
    "考虑激活函数的表示：\n",
    "\n",
    "<img src=\"img/3_18.png\" alt=\"Drawing\" style=\"width: 300px;\"/>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "177b5c0f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-24T14:18:22.554902Z",
     "start_time": "2022-11-24T14:18:22.545655Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3)\n",
      "(2,)\n",
      "(3,)\n",
      "[0.3 0.7 1.1]\n",
      "[0.57444252 0.66818777 0.75026011]\n"
     ]
    }
   ],
   "source": [
    "# 用NumPy多维数组来实现式\n",
    "X = np.array([1.0, 0.5])\n",
    "W1 = np.array([[0.1, 0.3, 0.5], [0.2, 0.4, 0.6]])\n",
    "B1 = np.array([0.1, 0.2, 0.3])\n",
    "\n",
    "print(W1.shape) # (2, 3)\n",
    "print(X.shape) # (2,)\n",
    "print(B1.shape) # (3,)\n",
    "\n",
    "A1 = np.dot(X, W1) + B1\n",
    "print(A1) # [0.3, 0.7, 1.1]\n",
    "\n",
    "# 第1层中激活函数的计算过程\n",
    "Z1 = sigmoid(A1)\n",
    "print(Z1) # [0.57444252, 0.66818777, 0.75026011]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd5692d",
   "metadata": {},
   "source": [
    "## 第1层到第2层的信号传递\n",
    "\n",
    "<img src=\"img/3_19.png\" alt=\"Drawing\" style=\"width: 300px;\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b277a72f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-24T14:23:07.858033Z",
     "start_time": "2022-11-24T14:23:07.847331Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3,)\n",
      "(3, 2)\n",
      "(2,)\n",
      "[0.51615984 1.21402696]\n",
      "[0.62624937 0.7710107 ]\n"
     ]
    }
   ],
   "source": [
    "# 这个实现和刚才的代码完全相同。\n",
    "# 由此可知，通过使用NumPy数组，可以将层到层的信号传递过程简单地写出来。\n",
    "\n",
    "W2 = np.array([[0.1, 0.4], [0.2, 0.5], [0.3, 0.6]])\n",
    "B2 = np.array([0.1, 0.2])\n",
    "print(Z1.shape) # (3,)\n",
    "print(W2.shape) # (3, 2)\n",
    "print(B2.shape) # (2,)\n",
    "\n",
    "A2 = np.dot(Z1, W2) + B2\n",
    "print(A2)\n",
    "Z2 = sigmoid(A2)\n",
    "print(Z2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eab75b5",
   "metadata": {},
   "source": [
    "## 从第2层到输出层的信号传递\n",
    "\n",
    "\n",
    "<img src=\"img/3_20.png\" alt=\"Drawing\" style=\"width: 300px;\"/>\n",
    "\n",
    "输出层的实现也和之前的实现基本相同。不过，最后的激活函数和之前的隐藏层有所不同。\n",
    "\n",
    "\n",
    "这里我们定义了identity_function()函数（也称为“恒等函数”），并将其作为输出层的激活函数。\n",
    "恒等函数会将输入按原样输出，因此，这个例子中没有必要特意定义identity_function()。这里这样实现只是为了和之前的流程保持统一。\n",
    "\n",
    "另外，图3-20中，输出层的激活函数用σ()表示，不同于隐\n",
    "藏层的激活函数h()（σ读作sigma）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5e442009",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-24T14:28:25.743316Z",
     "start_time": "2022-11-24T14:28:25.727711Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.31682708 0.69627909]\n",
      "[0.31682708 0.69627909]\n"
     ]
    }
   ],
   "source": [
    "def identity_function(x):\n",
    "    return x\n",
    "\n",
    "W3 = np.array([[0.1, 0.3], [0.2, 0.4]])\n",
    "B3 = np.array([0.1, 0.2])\n",
    "A3 = np.dot(Z2, W3) + B3\n",
    "print(A3)\n",
    "Y = identity_function(A3) # 或者Y = A3\n",
    "print(Y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf05bb88",
   "metadata": {},
   "source": [
    "## 代码实现汇总"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a525b39d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-24T14:32:04.102087Z",
     "start_time": "2022-11-24T14:32:04.074314Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.31682708 0.69627909]\n"
     ]
    }
   ],
   "source": [
    "# 权重和偏置的初始化，并将它们保存在字典变量network中。\n",
    "def init_network():\n",
    "    network = {}\n",
    "    network['W1'] = np.array([[0.1, 0.3, 0.5], [0.2, 0.4, 0.6]])\n",
    "    network['b1'] = np.array([0.1, 0.2, 0.3])\n",
    "    network['W2'] = np.array([[0.1, 0.4], [0.2, 0.5], [0.3, 0.6]])\n",
    "    network['b2'] = np.array([0.1, 0.2])\n",
    "    network['W3'] = np.array([[0.1, 0.3], [0.2, 0.4]])\n",
    "    network['b3'] = np.array([0.1, 0.2])\n",
    "    return network\n",
    "\n",
    "# 定义恒等函数\n",
    "def identity_function(x):\n",
    "    return x\n",
    "\n",
    "# 封装了将输入信号转换为输出信号的处理过程。\n",
    "def forward(network, x):\n",
    "    W1, W2, W3 = network['W1'], network['W2'], network['W3']\n",
    "    b1, b2, b3 = network['b1'], network['b2'], network['b3']\n",
    "    a1 = np.dot(x, W1) + b1\n",
    "    z1 = sigmoid(a1)\n",
    "    a2 = np.dot(z1, W2) + b2\n",
    "    z2 = sigmoid(a2)\n",
    "    a3 = np.dot(z2, W3) + b3\n",
    "    y = identity_function(a3)\n",
    "    return y\n",
    "\n",
    "# 调用函数\n",
    "network = init_network()\n",
    "x = np.array([1.0, 0.5])\n",
    "y = forward(network, x)\n",
    "print(y) # [ 0.31682708 0.69627909]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa332ea1",
   "metadata": {},
   "source": [
    "总结一下思路，每一层有两个步骤计算：\n",
    "1. 先做线性计算；\n",
    "2. 再做激活函数计算；（在最后的输出层，这里暂时使用了恒定函数，后面还有其他函数）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05032429",
   "metadata": {},
   "source": [
    "# 输出层的设计\n",
    "\n",
    "神经网络可以用在分类问题和回归问题上，不过需要根据情况改变输出层的激活函数。\n",
    "\n",
    "一般而言，回归问题用恒等函数，分类问题用softmax函数。\n",
    "\n",
    "恒等函数不用多说了，在输出层使用恒等函数时，输入信号会原封不动地被输出。在上面代码我们也见到过。这里主要来介绍softmax函数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a3f31b",
   "metadata": {},
   "source": [
    "## softmax 函数\n",
    "公式：\n",
    "\n",
    "<img src=\"img/formula_3_10.png\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    "\n",
    "- ak就是经过点积之后最后要output的值，在output之前需要经过softmax函数的处理；\n",
    "- exp(x)是表示ex的指数函数（e是纳皮尔常数2.7182 ...）。\n",
    "- 公式表示假设输出层共有n个神经元，计算第k个神经元的输出yk。\n",
    "- 如公所示，softmax函数的分子是输入信号ak的指数函数，分母是所有输入信号的指数函数的和。\n",
    "    - （其实简单理解就是每个分类的占比，总和为1）\n",
    "    \n",
    "- 如下图：softmax函数的输出通过箭头与所有的输入信号相连\n",
    "    \n",
    "<img src=\"img/3_22.png\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    "\n",
    "\n",
    "**softmax 函数的意义/目的**\n",
    "1. 输出y 加总之后和为1。。。。，这是为了归一化？？？\n",
    "2. 可能和求导有关。。。\n",
    "\n",
    "**softmax 函数的特性**\n",
    "1. softmax函数的输出是0.0到1.0之间的实数。并且，softmax 函数的输出值的总和是1。因为有了这个性质，我们才可以把softmax函数的输出解释为“概率”。\n",
    "2. 各个元素之间的大小关系也不会改变。这是因为指数函数（y = exp(x)）是单调递增函数。比如，a的最大值是第2个元素，y的最大值也仍是第2个元素。神经网络只把输出值最大的神经元所对应的类别作为识别结果。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a20971e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-25T00:26:37.229711Z",
     "start_time": "2022-11-25T00:26:37.186745Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.34985881 18.17414537 54.59815003]\n",
      "74.1221542101633\n",
      "[0.01821127 0.24519181 0.73659691]\n"
     ]
    }
   ],
   "source": [
    "# softmax 内部实现测试\n",
    "a = np.array([0.3, 2.9, 4.0])\n",
    "exp_a = np.exp(a) # 指数函数\n",
    "print(exp_a)\n",
    "\n",
    "sum_exp_a = np.sum(exp_a) # 指数函数的和\n",
    "print(sum_exp_a)\n",
    "\n",
    "y = exp_a / sum_exp_a\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7c4a0601",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-25T00:34:17.160666Z",
     "start_time": "2022-11-25T00:34:17.122141Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-34-2ee7f1f30449>:3: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(a) / np.sum(np.exp(a)) # softmax函数的运算，发现会有warning提示：overflow\n",
      "<ipython-input-34-2ee7f1f30449>:3: RuntimeWarning: invalid value encountered in true_divide\n",
      "  np.exp(a) / np.sum(np.exp(a)) # softmax函数的运算，发现会有warning提示：overflow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([nan, nan, nan])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([  0, -10, -20])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([9.99954600e-01, 4.53978686e-05, 2.06106005e-09])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 一般softmax函数溢出问题\n",
    "a = np.array([1010, 1000, 990])\n",
    "np.exp(a) / np.sum(np.exp(a)) # softmax函数的运算，发现会有warning提示：overflow\n",
    "\n",
    "# 解决溢出问题\n",
    "c = np.max(a) # 1010\n",
    "a - c\n",
    "np.exp(a - c) / np.sum(np.exp(a - c)) # 这样就解决了溢出问题！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4cc76cf6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-17T08:23:04.065129Z",
     "start_time": "2022-10-17T08:23:04.054480Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01821127 0.24519181 0.73659691]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# softmax 封装\n",
    "def softmax_old(a):\n",
    "    exp_a = np.exp(a)\n",
    "    sum_exp_a = np.sum(exp_a)\n",
    "    y = exp_a / sum_exp_a\n",
    "    return y\n",
    "\n",
    "# 优化：解决 溢出问题\n",
    "def softmax(a):\n",
    "    c = np.max(a)\n",
    "    exp_a = np.exp(a - c) # 解决溢出，加入一个常数（为负数），因为是分子分母同乘对结果没有影响；但是可以解决分子过大导致溢出问题；\n",
    "    sum_exp_a = np.sum(exp_a)\n",
    "    y = exp_a / sum_exp_a\n",
    "    return y\n",
    "\n",
    "a = np.array([0.3, 2.9, 4.0])\n",
    "y = softmax(a)\n",
    "print(y)\n",
    "print(np.sum(y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3d0114bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-17T09:27:20.195561Z",
     "start_time": "2022-10-17T09:27:20.018547Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.80134161e-05 2.12062451e-04 5.76445508e-04 1.56694135e-03\n",
      " 4.25938820e-03 1.15782175e-02 3.14728583e-02 8.55520989e-02\n",
      " 2.32554716e-01 6.32149258e-01]\n",
      "[0.         0.02222222 0.04444444 0.06666667 0.08888889 0.11111111\n",
      " 0.13333333 0.15555556 0.17777778 0.2       ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fdcf7137550>,\n",
       " <matplotlib.lines.Line2D at 0x7fdcf7137580>]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 多分类，对比softmax与线性的求和表现\n",
    "\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "x = np.arange(10)\n",
    "e = softmax(x)\n",
    "print(e)\n",
    "f = x/np.sum(x)\n",
    "print(f)\n",
    "\n",
    "plt.plot(x, e, x, f)\n",
    "\n",
    "# 总结：softmax 能够很明显体现出最大值。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2b7f41",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-17T10:36:29.992465Z",
     "start_time": "2022-10-17T10:36:29.973403Z"
    }
   },
   "source": [
    "# 案例：利用神经网络进行“手写数字识别”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4eb848ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-25T00:49:45.947601Z",
     "start_time": "2022-11-25T00:49:45.856623Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "(784,)\n",
      "(28, 28)\n"
     ]
    }
   ],
   "source": [
    "# MNIST数据集 导入\n",
    "\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 为了导入父目录的文件而进行的设定\n",
    "import numpy as np\n",
    "from dataset.mnist import load_mnist\n",
    "from PIL import Image\n",
    "\n",
    "def img_show(img):\n",
    "    pil_img = Image.fromarray(np.uint8(img))\n",
    "    pil_img.show()\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=True, normalize=False)\n",
    "# 参数normalize设置是否将输入图像正规化为0.0～1.0的值，这里没有设置，待会儿打印的数据可以直观看到；\n",
    "\n",
    "# 参数flatten设置是否展开输入图像（变成一维数组）。如果将该参数设置为False，则输入图像为1 × 28 × 28的三维数组；若设置为True，则输入图像会保存为由784个元素构成的一维数组。\n",
    "# 所以在这边就可以类似下面reshape的操作，转换成28×28的数组，这里为啥是三维数组？为啥多了一维？\n",
    "\n",
    "# 参数one_hot_label设置是否将标签保存为one-hot表示（one-hot representation）。\n",
    "# one-hot表示是仅正确解标签为1，其余皆为0的数组，就像[0,0,1,0,0,0,0,0,0,0]这样。当one_hot_label为False时，只是像7、2这样简单保存正确解标签；当one_hot_label为True时，标签则保存为one-hot表示。\n",
    "\n",
    "img = x_train[0] # x_train 中第一个图像元素的数据\n",
    "label = t_train[0] # 第一个图像元素的label，这里为 5\n",
    "print(label)  # 5，通过上面 one_hot_label 参数，可以设置为one-hot格式；\n",
    "\n",
    "print(img.shape)  # (784,)\n",
    "img = img.reshape(28, 28)  # 把图像的形状变为原来的尺寸\n",
    "print(img.shape)  # (28, 28)\n",
    "\n",
    "img_show(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9750e0d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-20T03:31:07.485775Z",
     "start_time": "2022-10-20T03:31:07.476824Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784,)\n",
      "(28, 28)\n",
      "(60000, 784)\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "# cc\n",
    "img2 = x_test[0]\n",
    "print(img2.shape)\n",
    "img2 = img2.reshape(28, 28) # 所以 reshape这一步还是非常重要的。\n",
    "print(img2.shape)\n",
    "\n",
    "# img_show(img2)\n",
    "\n",
    "# 这里也就明白了，一条：比如x_train[0] 数据表示一张图片；\n",
    "# 而x_train[0] 是 1×784 的结构，在reshape成28×28后，就形成了正方形排布的像素点；\n",
    "# 之后再通过 img_show 转换成图像；\n",
    "\n",
    "print(x_train.shape) # 而x_train 总共有60000个这样的图片；\n",
    "print(x_test.shape) # x_test 总共有10000个这样的图片；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8524d9b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-20T07:56:44.269248Z",
     "start_time": "2022-10-20T07:56:43.211275Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 784)\n",
      "(10000,)\n",
      "Accuracy:0.9352\n"
     ]
    }
   ],
   "source": [
    "# 神经网络的推理处理\n",
    "\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 为了导入父目录的文件而进行的设定\n",
    "import numpy as np\n",
    "import pickle\n",
    "from dataset.mnist import load_mnist\n",
    "from common.functions import sigmoid, softmax\n",
    "\n",
    "def get_data():\n",
    "    (x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, flatten=True, one_hot_label=False)\n",
    "    return x_test, t_test\n",
    "\n",
    "def init_network():\n",
    "    with open(\"sample_weight.pkl\", 'rb') as f:\n",
    "        network = pickle.load(f)\n",
    "    return network\n",
    "\n",
    "def predict(network, x):\n",
    "    W1, W2, W3 = network['W1'], network['W2'], network['W3']\n",
    "    b1, b2, b3 = network['b1'], network['b2'], network['b3']\n",
    "\n",
    "    a1 = np.dot(x, W1) + b1\n",
    "    z1 = sigmoid(a1)\n",
    "    a2 = np.dot(z1, W2) + b2\n",
    "    z2 = sigmoid(a2) # sigmoid 做激活函数\n",
    "    a3 = np.dot(z2, W3) + b3\n",
    "    y = softmax(a3) # softmax 做输出函数\n",
    "\n",
    "    return y\n",
    "\n",
    "x, t = get_data()\n",
    "print(x.shape) # 10000张图片，每张图片28*28像素\n",
    "print(t.shape) # 10000张图片对应的标签\n",
    "\n",
    "network = init_network()\n",
    "accuracy_cnt = 0\n",
    "for i in range(len(x)): # 一共有len(x)个图片，就进行这些次的循环来求精度；\n",
    "    y = predict(network, x[i]) # 每个x在0~9的概率\n",
    "    p= np.argmax(y) # 获取概率最高的元素的索引，cc：刚好这里索引对应的就是数字\n",
    "    if p == t[i]: # 然后和t[i]的标签进行对比；t现在还不是one-hot，就是某个值；\n",
    "        accuracy_cnt += 1\n",
    "\n",
    "print(\"Accuracy:\" + str(float(accuracy_cnt) / len(x)))\n",
    "\n",
    "\n",
    "# 使用normalize=True 正规化数据之后，\n",
    "# 1. 精度由 0.9207变化到 0.9352\n",
    "# 2. 没有正规化数据的话，计算log会有问题，提示：overflow encountered in exp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d91fef4a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-20T07:40:38.196293Z",
     "start_time": "2022-10-20T07:40:38.006307Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# cc：test\n",
    "def get_data2(normalize=False, flatten=False, one_hot_label=False):\n",
    "    (x_train, t_train), (x_test, t_test) = load_mnist(normalize=normalize, flatten=flatten, one_hot_label=one_hot_label)\n",
    "    return x_test, t_test\n",
    "\n",
    "test_x, test_t = get_data2(normalize=True, flatten=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2bea864e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-20T07:43:38.538295Z",
     "start_time": "2022-10-20T07:43:38.531815Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 1, 28, 28)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "08b2e590",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-20T07:43:10.951706Z",
     "start_time": "2022-10-20T07:43:10.872447Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.329412</td>\n",
       "      <td>0.725490</td>\n",
       "      <td>0.623529</td>\n",
       "      <td>0.592157</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.870588</td>\n",
       "      <td>0.996078</td>\n",
       "      <td>0.996078</td>\n",
       "      <td>0.996078</td>\n",
       "      <td>...</td>\n",
       "      <td>0.776471</td>\n",
       "      <td>0.776471</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.203922</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.262745</td>\n",
       "      <td>0.447059</td>\n",
       "      <td>0.282353</td>\n",
       "      <td>0.447059</td>\n",
       "      <td>...</td>\n",
       "      <td>0.898039</td>\n",
       "      <td>0.996078</td>\n",
       "      <td>0.996078</td>\n",
       "      <td>0.549020</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.082353</td>\n",
       "      <td>0.925490</td>\n",
       "      <td>0.996078</td>\n",
       "      <td>0.415686</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.325490</td>\n",
       "      <td>0.992157</td>\n",
       "      <td>0.819608</td>\n",
       "      <td>0.070588</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.913725</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.325490</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.996078</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.172549</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.996078</td>\n",
       "      <td>0.243137</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.019608</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.227451</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5         6         7         8         9   ...  \\\n",
       "0   0.0  0.0  0.0  0.0  0.0  0.0  0.000000  0.000000  0.000000  0.000000  ...   \n",
       "1   0.0  0.0  0.0  0.0  0.0  0.0  0.000000  0.000000  0.000000  0.000000  ...   \n",
       "2   0.0  0.0  0.0  0.0  0.0  0.0  0.000000  0.000000  0.000000  0.000000  ...   \n",
       "3   0.0  0.0  0.0  0.0  0.0  0.0  0.000000  0.000000  0.000000  0.000000  ...   \n",
       "4   0.0  0.0  0.0  0.0  0.0  0.0  0.000000  0.000000  0.000000  0.000000  ...   \n",
       "5   0.0  0.0  0.0  0.0  0.0  0.0  0.000000  0.000000  0.000000  0.000000  ...   \n",
       "6   0.0  0.0  0.0  0.0  0.0  0.0  0.000000  0.000000  0.000000  0.000000  ...   \n",
       "7   0.0  0.0  0.0  0.0  0.0  0.0  0.329412  0.725490  0.623529  0.592157  ...   \n",
       "8   0.0  0.0  0.0  0.0  0.0  0.0  0.870588  0.996078  0.996078  0.996078  ...   \n",
       "9   0.0  0.0  0.0  0.0  0.0  0.0  0.262745  0.447059  0.282353  0.447059  ...   \n",
       "10  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  0.000000  0.000000  0.000000  ...   \n",
       "11  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  0.000000  0.000000  0.000000  ...   \n",
       "12  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  0.000000  0.000000  0.000000  ...   \n",
       "13  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  0.000000  0.000000  0.000000  ...   \n",
       "14  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  0.000000  0.000000  0.000000  ...   \n",
       "15  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  0.000000  0.000000  0.000000  ...   \n",
       "16  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  0.000000  0.000000  0.000000  ...   \n",
       "17  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  0.000000  0.000000  0.000000  ...   \n",
       "18  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  0.000000  0.000000  0.000000  ...   \n",
       "19  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  0.000000  0.000000  0.000000  ...   \n",
       "20  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  0.000000  0.000000  0.000000  ...   \n",
       "21  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  0.000000  0.000000  0.000000  ...   \n",
       "22  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  0.000000  0.000000  0.000000  ...   \n",
       "23  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  0.000000  0.000000  0.000000  ...   \n",
       "24  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  0.000000  0.000000  0.000000  ...   \n",
       "25  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  0.000000  0.000000  0.000000  ...   \n",
       "26  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  0.000000  0.000000  0.000000  ...   \n",
       "27  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  0.000000  0.000000  0.000000  ...   \n",
       "\n",
       "          18        19        20        21   22   23   24   25   26   27  \n",
       "0   0.000000  0.000000  0.000000  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1   0.000000  0.000000  0.000000  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2   0.000000  0.000000  0.000000  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3   0.000000  0.000000  0.000000  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4   0.000000  0.000000  0.000000  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "5   0.000000  0.000000  0.000000  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "6   0.000000  0.000000  0.000000  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "7   0.000000  0.000000  0.000000  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "8   0.776471  0.776471  0.666667  0.203922  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "9   0.898039  0.996078  0.996078  0.549020  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "10  0.082353  0.925490  0.996078  0.415686  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "11  0.325490  0.992157  0.819608  0.070588  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "12  0.913725  1.000000  0.325490  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "13  0.996078  0.933333  0.172549  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "14  0.996078  0.243137  0.000000  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "15  0.733333  0.019608  0.000000  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "16  0.227451  0.000000  0.000000  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "17  0.000000  0.000000  0.000000  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "18  0.000000  0.000000  0.000000  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "19  0.000000  0.000000  0.000000  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "20  0.000000  0.000000  0.000000  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "21  0.000000  0.000000  0.000000  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "22  0.000000  0.000000  0.000000  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "23  0.000000  0.000000  0.000000  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "24  0.000000  0.000000  0.000000  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "25  0.000000  0.000000  0.000000  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "26  0.000000  0.000000  0.000000  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "27  0.000000  0.000000  0.000000  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[28 rows x 28 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "a = test_x[0].reshape(28, 28)\n",
    "pd.DataFrame(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bc173071",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-20T07:47:21.360883Z",
     "start_time": "2022-10-20T07:47:21.352518Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cc\n",
    "network['b2'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51169d1",
   "metadata": {},
   "source": [
    "### 批处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e74a5d94",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-17T11:01:43.110343Z",
     "start_time": "2022-10-17T11:01:42.640066Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.9352\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 为了导入父目录的文件而进行的设定\n",
    "import numpy as np\n",
    "import pickle\n",
    "from dataset.mnist import load_mnist\n",
    "from common.functions import sigmoid, softmax\n",
    "\n",
    "\n",
    "def get_data():\n",
    "    (x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, flatten=True, one_hot_label=False)\n",
    "    return x_test, t_test\n",
    "\n",
    "\n",
    "def init_network():\n",
    "    with open(\"sample_weight.pkl\", 'rb') as f:\n",
    "        network = pickle.load(f)\n",
    "    return network\n",
    "\n",
    "\n",
    "def predict(network, x):\n",
    "    w1, w2, w3 = network['W1'], network['W2'], network['W3']\n",
    "    b1, b2, b3 = network['b1'], network['b2'], network['b3']\n",
    "\n",
    "    a1 = np.dot(x, w1) + b1\n",
    "    z1 = sigmoid(a1)\n",
    "    a2 = np.dot(z1, w2) + b2\n",
    "    z2 = sigmoid(a2)\n",
    "    a3 = np.dot(z2, w3) + b3\n",
    "    y = softmax(a3)\n",
    "\n",
    "    return y\n",
    "\n",
    "\n",
    "x, t = get_data()\n",
    "network = init_network()\n",
    "\n",
    "batch_size = 100 # 批数量\n",
    "accuracy_cnt = 0\n",
    "\n",
    "for i in range(0, len(x), batch_size):\n",
    "    x_batch = x[i:i+batch_size] # for循环每次取100个，而不是每次取1个\n",
    "    y_batch = predict(network, x_batch)\n",
    "    p = np.argmax(y_batch, axis=1)\n",
    "    accuracy_cnt += np.sum(p == t[i:i+batch_size])\n",
    "\n",
    "print(\"Accuracy:\" + str(float(accuracy_cnt) / len(x))) # 和上面的结果一致"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "263a5ee0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-20T08:02:27.239916Z",
     "start_time": "2022-10-20T08:02:27.041985Z"
    }
   },
   "outputs": [],
   "source": [
    "x, _ = get_data()\n",
    "network = init_network()\n",
    "W1, W2, W3 = network['W1'], network['W2'], network['W3']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "93e1146c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-20T08:02:55.572168Z",
     "start_time": "2022-10-20T08:02:55.551563Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(784, 50)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(50, 100)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(100, 10)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape\n",
    "\n",
    "W1.shape\n",
    "\n",
    "W2.shape\n",
    "\n",
    "W3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b7ce0567",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-20T08:16:21.002599Z",
     "start_time": "2022-10-20T08:16:20.642114Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.9352\n"
     ]
    }
   ],
   "source": [
    "x, t = get_data()\n",
    "network = init_network()\n",
    "\n",
    "batch_size = 100 # 批数量\n",
    "accuracy_cnt = 0\n",
    "\n",
    "for i in range(0, len(x), batch_size):\n",
    "    x_batch = x[i:i+batch_size]    \n",
    "    y_batch = predict(network, x_batch) # predict 里面点积在x 变为二维之后依然成立；\n",
    "    p = np.argmax(y_batch, axis=1)\n",
    "    accuracy_cnt += np.sum(p == t[i:i+batch_size])\n",
    "\n",
    "print(\"Accuracy:\" + str(float(accuracy_cnt) / len(x)))\n",
    "\n",
    "# 得到的结果和 不用批处理的结果一致；\n",
    "# 不用批处理的话，相当于迭代10000次，使用了批处理迭代了100次，在每次迭代中用矩阵多维计算方法实现批处理！！！\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "61739902",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-20T08:09:04.710470Z",
     "start_time": "2022-10-20T08:09:04.700995Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "6000\n",
      "6100\n",
      "6200\n",
      "6300\n",
      "6400\n",
      "6500\n",
      "6600\n",
      "6700\n",
      "6800\n",
      "6900\n",
      "7000\n",
      "7100\n",
      "7200\n",
      "7300\n",
      "7400\n",
      "7500\n",
      "7600\n",
      "7700\n",
      "7800\n",
      "7900\n",
      "8000\n",
      "8100\n",
      "8200\n",
      "8300\n",
      "8400\n",
      "8500\n",
      "8600\n",
      "8700\n",
      "8800\n",
      "8900\n",
      "9000\n",
      "9100\n",
      "9200\n",
      "9300\n",
      "9400\n",
      "9500\n",
      "9600\n",
      "9700\n",
      "9800\n",
      "9900\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(x), batch_size):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75f078d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-17T11:26:15.822604Z",
     "start_time": "2022-10-17T11:26:15.818430Z"
    }
   },
   "source": [
    "## 额外的学习"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3925b0e",
   "metadata": {},
   "source": [
    "### 1.关于绝对路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f379eed2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-17T11:35:54.793737Z",
     "start_time": "2022-10-17T11:35:54.781871Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/matao/study/self_repository/deepLearning/ch03\n",
      "/Users/matao/study/self_repository/deepLearning\n",
      "/Users/matao/study/self_repository\n",
      "/Users/matao/opt/anaconda3/lib/python3.8/os.py\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# 在py文件这样写，但是在notebook不行\n",
    "# dataset_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "\n",
    "# 在notebook 要这样写：\n",
    "base_dir1 = os.path.dirname(os.path.realpath('file'))\n",
    "print(base_dir)\n",
    "\n",
    "base_dir2 = os.path.dirname(base_dir1)\n",
    "print(base_dir2)\n",
    "\n",
    "base_dir3 = os.path.dirname(base_dir2)\n",
    "print(base_dir3)\n",
    "\n",
    "# 获取os的路径\n",
    "path4 = os.__file__\n",
    "print(path4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c627ce61",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-17T11:48:50.821513Z",
     "start_time": "2022-10-17T11:48:50.816624Z"
    }
   },
   "source": [
    "### 2.frombuffer\n",
    "\n",
    "#### 形式\n",
    "\n",
    "numpy.frombuffer(buffer, dtype=float, count=-1, offset=0)\n",
    "\n",
    "#### 解释：\n",
    "\n",
    "将缓冲区解释为一维数组。\n",
    "\n",
    "#### 参数\n",
    "\n",
    "buffer ：buffer_like，公开缓冲区接口的对象。\n",
    "\n",
    "dtype ：data-type, 可选。返回array的数据类型;默认值:float。\n",
    "\n",
    "count ：int, 可选。要阅读的条目数。-1表示缓冲区中的所有数据。\n",
    "\n",
    "offset ：int, 可选。从这个偏移量(以字节为单位)开始读取缓冲区;默认值:0。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e198b159",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-17T11:54:59.656460Z",
     "start_time": "2022-10-17T11:54:59.636183Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bytes'>\n",
      "[1 2]\n",
      "[1 2 3]\n"
     ]
    }
   ],
   "source": [
    "s = b'hello world'\n",
    "print(type(s))\n",
    "np.frombuffer(s, dtype='S1', count=5, offset=6)\n",
    "\n",
    "\n",
    "b = np.frombuffer(b'\\x01\\x02', dtype=np.uint8)\n",
    "print(b)\n",
    "\n",
    "c = np.frombuffer(b'\\x01\\x02\\x03\\x04\\x05', dtype=np.uint8, count=3)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea32f338",
   "metadata": {},
   "source": [
    "### 3. reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "29824c1b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-17T12:00:27.179091Z",
     "start_time": "2022-10-17T12:00:27.169140Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4 5 6]\n",
      "[[1 2]\n",
      " [3 4]\n",
      " [5 6]]\n",
      "(3, 2)\n"
     ]
    }
   ],
   "source": [
    "c = np.array([1,2,3,4,5,6])\n",
    "d = c.reshape(-1, 2) # -1 代表“待定”，根据第二个数字（2）再推算得出。\n",
    "print(c)\n",
    "print(d)\n",
    "print(d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "06857639",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-17T12:04:16.650471Z",
     "start_time": "2022-10-17T12:04:16.612671Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  2]\n",
      " [ 3  4]\n",
      " [ 5  6]\n",
      " [ 7  8]\n",
      " [ 9 10]\n",
      " [11 12]]\n",
      "[[ 1  2  3]\n",
      " [ 4  5  6]\n",
      " [ 7  8  9]\n",
      " [10 11 12]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 12 into shape (5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-79-ace4026f443e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 12 into shape (5)"
     ]
    }
   ],
   "source": [
    "# reshape(-1, n) 变成 (total/n, n)\n",
    "\n",
    "c = np.array([1,2,3,4,5,6,7,8,9,10,11,12])\n",
    "d = c.reshape(-1, 2)\n",
    "print(d)\n",
    "\n",
    "e = c.reshape(-1, 3)\n",
    "print(e)\n",
    "\n",
    "f = c.reshape(-1, 5) # 当12个元素并不能重组成 ?×5 的结构是会报错\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b40999f",
   "metadata": {},
   "source": [
    "### 4. 关于one hot实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "06f79346",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-17T12:14:25.978903Z",
     "start_time": "2022-10-17T12:14:25.957568Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "0\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "2\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "3\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "X = np.array([1,2,3,1])\n",
    "print(X.size)\n",
    "\n",
    "T = np.zeros((X.size, 10))\n",
    "print(T)\n",
    "\n",
    "for idx, row in enumerate(T):\n",
    "    print(idx)\n",
    "    print(row)\n",
    "    row[X[idx]] = 1\n",
    "    print(row)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2528ffde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab8d65e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb95c36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
